---
title: "Linear Models - Start to Finish"
author: "Cody Flagg"
date: "June 24th, 2014"
output: pdf_document
---

## Strategy:

1) Explore Data Structure
2) Explore Data Patterns (EDA)
3) Fitting Linear Model(s)
3b) Assessing Linear Models
4) Comparing Multiple Models
5) Examining Variable Importance and Model Predictions
5a) Predict New, or original, data to understand model results
5b) Examine scaled model parameters

This example is from a book on Mixed Effects Modeling in R. The specific data example is described below. 

__Note__: a "GAM" is a "generalized additive model", a special case of a linear regression. We will analyze this dataset with a simple multiple linear regression (MLR) rather than a GAM to start with, as GAMs are a bit more complicated. The most basic difference between a GAM and an MLR is that MLRs essentially fit "straight lines" to the predictor variables and can use categorical data, whereas a GAM can fit non-linear curves to predictor variables and cannot use categorical data. 

__The Goal__: Explore which variables drive species richness, and by how much. 

(from page 63 of Zuur's "Mixed Effects Models..." book)

In this section, we show how confusing GAM becomes if you ignore this step
of avoiding correlated explanatory variables. We use a plant vegetation data set for
illustration. Sikkink et al. (2007) analysed grassland data from a monitoring programme
from two temperate communities in Montana, USA: Yellowstone National
Park and National Bison Range. The aim of the study was to determine whether the
biodiversity of these bunchgrass communities changed over time and if they did,
whether the changes in biodiversity relate to specific environmental factors. Here,
we use the Yellowstone National Park data. Sikkink et al. (2007) quantified biodiversity
using species richness to summarise the large number of species: ninety
species were identified in the study. Richness is defined as the different number of
species per site. The data were measured in eight different transects and each transect
was measured repeatedly over time with time intervals of about four to ten
years. For the moment, we ignore the temporal aspects of the data. And, instead of
using all 20 or so explanatory variables, we use only those explanatory variables that
Sikkink et al. (2007) identified as important. Figure 3.18 shows a scatterplot of all
the variables used in this section. The response variable is species richness for the
64 observations, and the explanatory variables are rock content (ROCK), litter content
(LITTER), bare soil (BARESOIL), rainfall in the fall (FallPrec), and maximum
temperature in the spring (SprTmax). The correlation between ROCK and LITTER
is reasonably high with a Pearson correlation of -0.7.

```{r}
# data source: 
# Alain Zuur Book: http://www.highstat.com/book2.htm
# the "~" indicates a relative path i.e. a folder path that is potentially shared across computers, but with different use
veg <- read.table("~/GitHub/AvalonSoilProject/code_challenges/Vegetation.txt", header = T)
```

## 1) Explore Data Structure

* What are the variable names?
* What are some summary statistics?
* Are there any structural issues e.g. missing values, NA's, mixed negative and positive values, categorical variables??

```{r}
names(veg)
summary(veg)
```

* Now, we can remove NA's
* Not always a good idea, as this will remove ANY ROW with an NA, so you could be tossing out rows that still have data in other columns.
* In this case, they are missed sampling years. 

```{r}
veg <- na.omit(veg) # remove NA's, mostly years with no data
```

# 2) Exploratory Data Analysis (EDA): foundations of building new variables and models

### What to look for:

* Variables with dense, tightly clustered distributions - these need transforming
* Variables with lots of variation - these are sometimes better for prediction than variables with low variance
* Variables that are collinear - these variables should never be in the same model (they will 'inflate' the importance of a variable)
* Outliers
* Are there distinct groups or clouds of datapoints? This may imply another unseen physical structure to the data i.e. data derived from different ecosystems or treatments
* Are there lots of zeros or perhaps ordinal (ranked) rather than continuous data?
* Are observations independent? i.e. is there a time, spatial, or relational component driving variations?

```{r}
library(car)

# do all variables - have to use "as.formula" to leave quotes out - can also use to copy-paste a nicer formula without typing out
all_var = as.formula(paste("~", paste(names(veg),collapse = "+")))

# can print 'all_var' and copy-paste the text as input for a model without having to re-type all of the variable names

# plot this
scatterplotMatrix(all_var, data = veg, reg.line = lm, smoother = FALSE)

scatterplotMatrix(~Richness + ROCK + LITTER + BARESOIL + FallPrec + SprTmax, data = veg, smoother = FALSE)
```

### Conclusions from EDA: 

* ROCK and LITTER are highly correlated, they should not be included together in a single model. 
* BARESOIL and SprTmax appear to have some correlation, but the scatter seems much larger. 
* Several outliers appear at the edges of quite a few scatterplots.

## Build a Model
### Model 1 - one variable regression

```{r}
# How strongly does spring max temperature drive species richness?
m1.temp <- lm(Richness ~ SprTmax, data = veg) # fit the model
summary(m1.temp) # examine the summary statistics

```

### Model 1 - Model Diagnostics

__Things to Look For__
* _Residuals_ should be homogeneous or without strong patterns (i.e. the amount of variance should be similar across all values)
  * This plot is good for examining the independence of the data (Qian, pg. 137)
* _Normal Q-Q_ plot should show most points falling along the 1-1 line. If there is large deviation at the tails, you may need to transform variables.
  * This plot is good for checking that the residuals are normally distributed (Qian, pg. 137)
* _Scale-Location_ shows how large squared residuals are for a specific value; numbered points highlight potential outliers.
* _Residuals vs. Leverage_ is similar to the last plot; points that fall outside of Cook's distance have too much leverage as outliers and may need to be removed. 
* __Fitted Values Minus Mean vs. Residuals-Fitted__ rfsplot() in R
  * Qian pg.139, figure 5.9

```{r}
plot(m1.temp)
```

### Model 2 - Build another single-variable model for comparison purposes

```{r}
m1.litter <- lm(Richness ~ LITTER, data = veg)
summary(m1.litter)
plot(m1.litter)
```

### Now compare the two models - a few ways to do this

__Method 1: Akaike's Information Criterion (AIC)__

_AIC_ is used to compare models based on their complexity (i.e. the number of parameters) and their overall fit (i.e. the residuals or leftover variance). More complex models are penalized more than simpler models. AIC produces a single value that can be used to compare across models. Te AIC value itself is subject and does not matter on its own, it must be compared to other similar models where a lower AIC value means a "better" model. 

AIC = 2*k - 2*ln*(model likelihood)

Where,

k = the number of parameters/predictors
ln = natural log
likelihood = the maximum likelihood value of the model

AIC can be applied to Linear regression: 

AIC = 2k + n Log(RSS/n)

Where,

n = the number of observations
RSS = the residual sum of squares

```{r}
AIC(m1.temp, m1.litter)
```
__Method 2: Examining Model Predictions__

* Can our model predict our own data? If not, it's probably not a good model.
* All model objects in R should be able to produce predictions with predict()
  * Also called "fitted values" i.e. predictions of your response variable
  * Using predict() with no newdata will produce predictions with the original data

```{r}
par(mfrow=c(1,2))
# plot the temperature model
predict(m1.temp) # gives the predicted values
plot(predict(m1.temp)~veg$Richness, xlim=c(0,25), ylim=c(0,25)) # plot against observed richness values
abline(0,1) # the 1:1 line

# plot the litter model
plot(predict(m1.litter)~veg$Richness, xlim=c(0,25), ylim=c(0,25))
abline(0,1)

```

# Assessing Variable Importance

* Build a multiple regression model (i.e. more than one predictor variable)

```{r}
# 
m2.all <- lm(Richness ~ SprTmax + FallPrec + BARESOIL, data = veg)
summary(m2.all)
```

* Various diagnostic prediction plots can show you how much of an effect a predictor will have on the response

* __Marginal Plots__ show you how each predictor influences the response _on its own_ i.e. without the other variables present

```{r}
car::marginalModelPlots(m2.all) #only marginal plots
```

* __Conditional Plots__ show you how much each predictor influences the response _while accounting for_ the other predictors

```{r}
# visualize effects - this looks similar to a "partial regression/residual plot"
# http://www.itl.nist.gov/div898/software/dataplot/refman1/auxillar/partregr.htm
car::crPlots(m2.all, smoother = NULL) # component+residual plots i.e. partial residuals

##### Other useful functions
# car::avPlots(m2.all) # conditional plots i.e. added-variable plots
# car::influencePlot(m2.all)
# car::leveragePlot(m2.all)
# car::mcPlot()
```

* Finally, you can visualize the effects of each variable by looking at the model predictions from different, perhaps new, data
* Spring Max Temp looks to be a pretty influential variable, what happens to Richness if the max temp reaches 20 degrees C in the future?

```{r}
par(mfrow=c(1,1))
# create a new data frame with an expanded temperature range
# keep fall precip and baresoil constant, or else we have to make multiple graphs
nd = with(veg, expand.grid(SprTmax = seq(8, 22, by = 2),
                           FallPrec = mean(FallPrec),
                           BARESOIL = mean(BARESOIL)))

# nlcd
# CR 
# bedrock 


# make predictions with "new" data
temp_pred = predict(m2.all, newdata = nd, se.fit = TRUE)

# append to previous data frame
pred1 = data.frame(SprTmax = nd$SprTmax, Richness = temp_pred$fit, Richness.se = temp_pred$se.fit)

# now plot the predicted richness with 95% confidence intervals
plot(Richness ~ SprTmax, data = pred1, type = "l") # the predicted richness
upp = pred1$Richness + 1.92*pred1$Richness.se # Upper conf interval, 1.92 is the t-value for a 95% confidence interval
lwr = pred1$Richness - 1.92*pred1$Richness.se # lower conf interval
lines(upp ~ pred1$SprTmax, lty = 2, col = "red") # add the upper line
lines(lwr ~ pred1$SprTmax, lty = 2, col = "red") # add the lower line
```

layout(matrix(c(1,2,1,3,1,4),3,2,byrow=TRUE),TRUE)








